---
title: "Financial Analytics - Trabalho Final"
authors:
  - name: Michel Maurice Conjaud
  - name: Hélio Pereira Oliveira
  - name: Renan Cabral
  - name: Tiago Evangelista Pardo
format:
  html:
    code-fold: true
    embed-resources: true
    smooth-scroll: true
    theme: cerulean
    toc: true
    toc-expand: true
    toc-title: "Sumário"
    toc_float: true

execute:
  freeze: true
  warning: false
  cache: true
---

# 0. Bibliotecas e Importação de Dados

Bibliotecas
```{r bibliotecas}
#| output: false
library(ggplot2)
library(fpp3)
library(rugarch)
library(tsibble)
library(yfR)
library(zoo)
library(xts)
library(lubridate)
library(patchwork)
library(lmtest)
library(fGarch)
library(xts)
library(FinTS)
library(tidyquant)
library(plotly)
library(timetk)

```


Seleção das Ações/Ativos e definição da data de início: 01/01/2019
```{r importacao dados}
#| output: false

 
data_inicio <- '2019-01-01'
 

ativos <- c(
  "NVDC34.SA",
  "BCSA34.SA", 
  "AMZO34.SA",
  "RENT3.SA",
  "PRIO3.SA",
  "TASA4.SA"
)
 

# Importando base da API do Yahoo

#| output: false



da <- yfR::yf_get(
    ativos,
    first_date = data_inicio,
    last_date = Sys.Date(),
    bench_ticker = "^BVSP",
    type_return = "log",
    freq_data = "daily",
    do_complete_data = TRUE
)    %>% 
    select( ticker, ref_date, price_adjusted, ret_closing_prices )
 
        
# Capturando menor data da base 
data_corte <- da |>
  dplyr::group_by(ticker) |>
  dplyr::filter(ref_date == min(ref_date)) |>
  dplyr::ungroup() |>
  with(max(ref_date))
# Filtrando base com data mínima
da_train <- da |>
  dplyr::filter(ref_date > data_corte) 

# Transformando em Tsibble
da_tsibble <- da_train |>
  as_tsibble(key = ticker, index = ref_date, regular = FALSE)


retornos_mercado_log  <- yfR::yf_get(
    '^BVSP',
    first_date = data_inicio,
    last_date = Sys.Date(),
    bench_ticker = "^BVSP",
    type_return = "log",
    freq_data = "daily",
    do_complete_data = TRUE
    )  %>% 
    select(ref_date, ret_closing_prices)  %>%
    filter(ref_date > data_corte)  %>%  
    na.omit()  %>% 
    distinct(ref_date, .keep_all = TRUE)


retornos_mercado_arit  <- yfR::yf_get(
    '^BVSP',
    first_date = data_inicio,
    last_date = Sys.Date(),
    bench_ticker = "^BVSP",
    type_return = "arit",
    freq_data = "daily",
    do_complete_data = TRUE
    )  %>% 
    select(ref_date, ret_closing_prices)  %>%
    filter(ref_date > data_corte)  %>%  
    na.omit()  %>% 
    distinct(ref_date, .keep_all = TRUE)


retornos_carteira_arit <- yfR::yf_get(
    ativos,
    first_date = data_inicio,
    last_date = Sys.Date(),
    bench_ticker = "^BVSP",
    type_return = "arit",
    freq_data = "daily",
    do_complete_data = TRUE
    ) %>% 
    select( ref_date, ret_closing_prices )  %>% 
    na.omit()
```

# 1. Gráficos de Preço, Retorno e Avaliação de Heterodasticidade Condicional

## 1.1. Gráfico de preços


```{r funcao legenda}

#Função para formatar legenda
quarter_label <- function(x) {
  paste0(year(x), "Q", quarter(x))
}  
```

```{r serie preco}
#| fig-width: 7
#| fig-height: 10

#criando gráfico da série de preços
da_tsibble |>
  autoplot(price_adjusted, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1)+
  scale_x_date(date_breaks = "4 months", label=quarter_label) +
  labs ( title = "Série de Preço", y = "Preço", x = "Data") +
 
  theme(
    plot.title = element_text(hjust = .5),
    axis.text.x = element_text(hjust = 1, angle = 45)
  )
 
```  

## 1.2. Log Retornos

```{r serie log retornos}
#| fig-width: 7
#| fig-height: 10
#| 
#criando gráfico da série de retornos
da_tsibble |>
  autoplot(ret_closing_prices, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1) +
  scale_x_date(date_breaks = "3 months", labels = quarter_label) +
  labs ( title = "Série de Log Retornos", y = "Log Retornos", x = "Data") +
  theme(plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(hjust = 1, angle = 45)
  )

```

## 1.3 Avaliando heterocedasticidade condicional

Criação do log retorno ao quadrado (proxi da volatilidade)

```{r plot dos retornos ao quadrado}
#| fig-width: 7
#| fig-height: 10

da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2) |>
  autoplot(ret2, colour = "black") +
  facet_wrap(~ticker, ncol = 1)

```

**Verificando a existência de heterodasticidade condicional através dos seguintes métodos:**

* 1.2.1. ACF dos retornos quadráticos

* 1.2.2. Teste Ljung-Box dos retornos quadráticos

* 1.2.3. Teste Langrange Multiplier

### 1.2.1. ACF dos retornos ao quadrado

```{r criando ret quadrado}
# Gerando variável dos retornos quadráticos
da_tsibble  <-  da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2)
```

```{r acf retornos ao quadrado}
#| fig-width: 7
#| fig-height: 10

#ACF dos retornos ao quadrado
da_tsibble |>
  ACF(ret2) |>
  autoplot()
```

**Interpretação**
* AMZO3, BCSA3, PRIO3 e RENT3 mostram autocorrelações significativas nos primeiros lags, indicando que a volatilidade desses retornos pode ser dependente no tempo. 

* NVCD, por outro lado, não apresenta uma dependência temporal forte, sugerindo ausência de heterocedasticidade significativa. 

* TASA4 tem algumas autocorrelações significativas, mas menos pronunciadas em comparação com as outras séries.

### 1.2.2. Teste Ljung-Box
```{r teste ljung box}

resultados <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)
  
  # Realizar o teste Box-Ljung
  box_test_result <- Box.test(da_tsibble_filtered$ret2, type = "Ljung-Box")
  
  # Adicionar o resultado ao dataframe de resultados
  resultados <- rbind(resultados, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = box_test_result$p.value 
                                          ))
}

print(resultados)
```

**Interpretação**
* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, RENT3.SA, PRIO3.SA e TASA4.SA, AMZO34.SA

### 1.2.3. Teste Lagrange Multiplier
```{r teste lm}


resultados_lm <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)

  teste_lm <- ArchTest(da_tsibble_filtered$ret_closing_prices)

  # Adicionar o resultado ao dataframe de resultados
  resultados_lm <- rbind(resultados_lm, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = teste_lm$p.value 
                                          ))
}

print(resultados_lm)
```

**Interpretação**
* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, AMZO34.SA, RENT3.SA, PRIO3.SA, e TASA4.SA

# 2. Ajustando modelos Arch / Garch

## 2.1. Ajuste

```{r modelo garch para cada empresa}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()
resultados_tidy <- list()

distribuicao_erro  <- c("norm", "std")

for (empresa in unique(da_tsibble$ticker)) {
  retornos <- da_tsibble %>%
  subset(ticker== empresa) %>%
  select(ref_date,ret_closing_prices)
ret <- xts(retornos[,-1],order.by = ymd(retornos$ref_date))[-1,]
ret2 = ret**2
  # Loop pelos parâmetros de tipo de distribuição e m e n
  for (distribuicao in distribuicao_erro) {
    for (m in 1:3) {
      for (n in 0:3) {
      
        # Definir a fórmula do modelo com os parâmetros m e n atuais
        formula_garch <- paste0("~garch(", m, ",", n, ")")
        # Ajustar o modelo GARCH
        modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                                 include.mean = TRUE, cond.dist = distribuicao)
        # Armazenar o modelo ajustado na lista para visualização detalhada
        modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao, "_", empresa)]] <- modelo_atual
        # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
        ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao, "_", empresa)]] <- modelo_atual@fit$ics
    }
  }
}
  # Formatando resultados para melhor visualização 
  for (nome_modelo in names(ics_modelos_garch)) {
    valores <- ics_modelos_garch[[nome_modelo]]
    df <- data.frame(
      AIC = valores["AIC"],
      BIC = valores["BIC"]
    )
      resultados_tidy[[nome_modelo]] <- df
  }
} 

resultados_tidy_df <- do.call(rbind, resultados_tidy) %>% 
  rownames_to_column()  %>% 
    separate(rowname, c("Modelo", "m", "n", "dist", "ticker"),
    sep = "_")  %>% 
    arrange(AIC)  %>% 
    distinct(ticker, .keep_all = TRUE)

resultados_tidy_df
```

## 2.2. Análise dos resíduos
```{r analise dos residuos}

residuos <- list()
par(mfrow = c(6, 1))

# Iterando sobre cada linha do data frame `resultados_tidy_df2`
for (i in 1:nrow(resultados_tidy_df2)) {
  
  # Concatenando o nome do modelo 
  model_name <- paste0(resultados_tidy_df2$Modelo[i], "_", 
                       resultados_tidy_df2$m[i], "_", 
                       resultados_tidy_df2$n[i], "_", 
                       resultados_tidy_df2$dist[i], "_", 
                       resultados_tidy_df2$ticker[i])
  
  # Checando se o modelo está entre os melhores
  if (model_name %in% names(modelos_garch)) {
    # Acessando os melhores modelos e calculando os resíduos
    current_model <- modelos_garch[[model_name]]
    residuos[[model_name]] <- residuals(current_model, standardize=TRUE)
    
    # Plotando os resíduos
    ts.plot(residuos[[model_name]], main = model_name)
  }
}
```

**Interpretação**
* Padrões: Não foi encontrado padrões claros, o que é um bom sinal. Isso sugere que os modelos estão capturando bem a estrutura dos dados.
* Outliers: Todos os gráficos têm alguns outliers, o que faz sentido em séries financeiras. 
* Heterocedasticidade: três ações mostram variações na amplitude dos resíduos, sugerindo que pode haver alguma heterocedasticidade residual (RENT3.SA & NVDC334.SA & BCSA34.SA). 

# 3. Previsão da volatilidade dos Ativos

```{r previsao dos ativos}
# Dados de exemplo (volatilidade_passo_frente)
volatilidade_passo_frente <- data.frame(
  Modelo = c("garch", "garch", "garch", "garch", "garch", "garch"),
  m = c(1, 1, 2, 1, 1, 1),
  n = c(2, 1, 1, 1, 1, 1),
  dist = c("std", "std", "std", "std", "std", "std"),
  ticker = c("AMZO34.SA", "BCSA34.SA", "RENT3.SA", "TASA4.SA", "NVDC34.SA", "PRIO3.SA"),
  AIC = c(-4.853336, -4.751056, -4.609009, -4.227347, -4.109136, -4.106262),
  BIC = c(-4.826964, -4.729079, -4.582637, -4.205371, -4.087160, -4.084286)
)

# Função para prever a volatilidade um passo à frente
prever_volatilidade <- function(ticker, m, n, dist) {
  # Simulação de dados de retorno (substitua com seus próprios dados)
  set.seed(123)
  returns <- rnorm(1000)

  # Configuração do modelo GARCH
  spec <- ugarchspec(
    variance.model = list(model = "sGARCH", garchOrder = c(m, n)),
    mean.model = list(armaOrder = c(0, 0)),
    distribution.model = dist
  )
  
  # Ajustar o modelo GARCH
  fit <- ugarchfit(spec = spec, data = returns)
  
  # Prever a volatilidade um passo à frente
  forecast <- ugarchforecast(fit, n.ahead = 1)
  sigma_forecast <- sigma(forecast)
  
  return(sigma_forecast)
}

# Loop para prever a volatilidade para cada modelo na lista
volatilidade_passo_frente$volatilidade_forecast <- NA

for (i in 1:nrow(volatilidade_passo_frente)) {
  ticker <- volatilidade_passo_frente$ticker[i]
  m <- volatilidade_passo_frente$m[i]
  n <- volatilidade_passo_frente$n[i]
  dist <- volatilidade_passo_frente$dist[i]
  
  volatilidade <- prever_volatilidade(ticker, m, n, dist)
  volatilidade_passo_frente$volatilidade_forecast[i] <- volatilidade
}

# Mostrar os resultados
print(volatilidade_passo_frente)

```

## 4.0 Comparar volatilidades entre os retornos selecionados (quais são maiores e menores, relacionando com algum storytelling);

* Maior Volatilidade: Amazon possui a maior volatilidade, refletindo seu alto nível de exposição ao mercado global e inovações tecnológicas.

* Menor Volatilidade: Banco Santander, Taurus, Nvidia, e Prio apresentam menor volatilidade, sugerindo operações estáveis e previsíveis em seus respectivos setores.

* Volatilidade Intermediária: Localiza tem uma volatilidade moderada, compatível com o setor de mobilidade que combina demanda estável com variações econômicas.

* Obs: NVIDIA está surfando o boom de IA, alcançando os USDD3Tri de valor de mercado, tendência de continuar subida de preço. 
* Obs: Santander, bancos tendem a ser mais estáveis no mercado brasileiro. 

## 4.2. Modelagem Garch do Portfolio
```{r modelagem garch portfolio}
modelos_garch_portfolio <- list()
ics_modelos_garch_portfolio  <- list()
resultados_tidy_portfolio <- list()


for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {
    
      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(
        formula = as.formula(formula_garch),
        data = retorno_ponderado_portfolio$retornos,
        trace = FALSE,          
        include.mean = TRUE, 
        cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch_portfolio[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch_portfolio[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}
# Formatando resultados para melhor visualização 
  for (nome_modelo in names(ics_modelos_garch_portfolio)) {
    valores <- ics_modelos_garch_portfolio[[nome_modelo]]
    df <- data.frame(
      AIC = valores["AIC"],
      BIC = valores["BIC"]
    )
      resultados_tidy_portfolio[[nome_modelo]] <- df
}

resultados_tidy_df_portfolio <- do.call(rbind, resultados_tidy_portfolio)%>% 
  rownames_to_column()  %>% 

    arrange(AIC)  %>% 
    slice(1)

resultados_tidy_df_portfolio
```

## 4.3. Forecast do Portfólio

```{r forecast portfolio}
forecast_volatilidade_portifolio <- predict(modelos_garch_portfolio$garch_1_1_std, n.ahead = 1)
forecast_volatilidade_portifolio
```
formatando para wide e transformando em formato objeto xts
```{r}
 
portfolio_wide_xts  <-  portfolio %>% 
  spread(ticker, value = ret_closing_prices)  %>% 
    tk_xts()
# Retirando coluna de data
portfolio_wide_xts <- portfolio_wide_xts[,-7]
# Convertendo colunas para numéricas
portfolio_wide_xts <- apply(portfolio_wide_xts, 2, as.numeric)

 
```


### Matriz covariância
```{r matriz covariancia}
cov_mat <- cov(portfolio_wide_xts) * 252
print(round(cov_mat,4))
```

### Media de retornos
```{r media de retornos portfolio }
media_retornos  <- colMeans(portfolio_wide_xts)
media_retornos
``` 

### Risco (Desvio Padrão)
```{r risco portfolio}
risco_portfolio  <- sqrt(t(pesos) %*% (cov_mat %*% pesos))
```

### Sharpe ratio
```{r sharpe ratio}
sharpe_ratio  <- media_retornos / risco_portfolio
```

# Otimização do Portfólio
```{r otimizacao portfolio}

numero_simulacoes_portfolio = 5000

simulacao_retornos <- function(i) {
  pesos <- runif(length(ativos))
  pesos <- pesos / sum(pesos)
  retorno_portfolio <- sum(pesos * media_retornos)
  desvio_padrao_portfolio <- as.numeric(sqrt(t(pesos) %*% (cov_mat %*% pesos)))
  sr <- retorno_portfolio / desvio_padrao_portfolio

  pesos |>
    purrr::set_names(ativos) |>
    tibble::enframe() |>
    tidyr::pivot_wider() |>
    dplyr::mutate(
      return = retorno_portfolio,
      risk = desvio_padrao_portfolio,
      sharpe = sr
    )
}

portfolio_values <- purrr::map(1:2000, simulacao_retornos, .progress = TRUE) |>
  bind_rows(.id = "run")

min_var <- portfolio_values[which.min(portfolio_values$risk),]
max_sr <- portfolio_values[which.max(portfolio_values$sharpe),]

```

```{r grafico min var}

min_var |>
  pivot_longer(2:7) |>
  mutate(name = forcats::fct_reorder(name, value)) |>
  ggplot(aes(name, value)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  labs(
    x = "Asset",
    y = "Weight",
    title = "Minimum variance portfolio weights"
  )


```

```{r grafico max var}
max_sr |>
  pivot_longer(2:7) |>
  mutate(name = forcats::fct_reorder(name, value)) |>
  ggplot(aes(name, value)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  labs(
    x = "Asset",
    y = "Weight",
    title = "Tangency portfolio weights"
  )
```


```{r grafico retornos risco}
portfolio_values |>
  ggplot(aes(x = risk, y = return, color = sharpe)) +
  geom_point() +
  theme_classic() +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = scales::percent) +
  labs(
    x = 'Risk',
    y = 'Returns',
    title = "Portfolio Optimization & Efficient Frontier"
  ) +
  geom_point(
    aes(x = risk, y = return),
    data = min_var,
    color = 'red',
    size = 3
  ) +
  geom_point(
    aes(x = risk, y = return),
    data = max_sr,
    color = 'orange',
    size = 3
  )
```




